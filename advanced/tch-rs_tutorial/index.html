<!DOCTYPE html>
<html class="writer-html5" lang="pt_BR" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>tch-rs-example MNIST - Tutoriais do NPAD</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "tch-rs-example MNIST";
        var mkdocs_page_input_path = "advanced\\tch-rs_tutorial.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Tutoriais do NPAD
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Buscar documentos" aria-label="Buscar documentos" title="Digite o termo a ser buscado aqui" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Menu de navegação">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Início</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Iniciante</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/superpc_introduction_part_1/">Introdução ao supercomputador - Parte&nbsp;1</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/superpc_introduction_part_2/">Introdução ao supercomputador - Parte&nbsp;2</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/gnome_files/">Copiando arquivos através de uma interface gráfica Gnome Files (linux)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/winscp_tutorial/">Copiando arquivos através de uma interface gráfica WinSCP (Windows)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/scp_tutorial/">Tutorial do scp</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/rsync_tutorial/">Tutorial do rsync</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/putty_tutorial/">Tutorial do PuTTy</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../beginner/mobaxterm_tutorial/">Tutorial do MobaXterm</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Intermediário</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../intermediate/superpc_introduction_part_3/">Introdução ao supercomputador - Parte&nbsp;3</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../intermediate/slurm_commands/">Comandos do supercomputador</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../intermediate/install_apps/">Instalação de programas no supercomputador</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Avançado</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../openmp_tutorial/">Tutorial de OpenMP</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../mpi_tutorial/">Tutorial de MPI</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">tch-rs-example MNIST</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#instalando-dependencias">Instalando dependências</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#criando-um-aplicacao-em-rust-para-treinar-uma-rede-neural">Criando um aplicação em rust para treinar uma rede neural</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#carregamento-do-conjunto-de-dados-mnist">Carregamento do conjunto de dados MNIST</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#configuracao-do-dispositivo-de-processamento">Configuração do dispositivo de processamento</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#criando-um-modelo-deep-learning">Criando um modelo deep learning</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#treinamento">Treinamento</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#executando-a-aplicacao-com-cuda-no-supercomputador">Executando a aplicação com cuda no supercomputador</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../jupyter_tutorial/">Usando o Jupyter no supercomputador</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Menu de navegação em dispositivo móvel">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Tutoriais do NPAD</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Documentos"></a> &raquo;</li>
          <li>Avançado &raquo;</li>
      <li>tch-rs-example MNIST</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="tch-rs-example-mnist">tch-rs-example MNIST<a class="headerlink" href="#tch-rs-example-mnist" title="Permanent link">&para;</a></h1>
<p>Nesse tutorial você irá aprender a usar a partição <strong>gpu</strong> e rust  para treinar um modelo de deep learning para resolver o <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>.</p>
<div class="toc">
<ul>
<li><a href="#tch-rs-example-mnist">tch-rs-example MNIST</a><ul>
<li><a href="#instalando-dependencias">Instalando dependências</a></li>
<li><a href="#criando-um-aplicacao-em-rust-para-treinar-uma-rede-neural">Criando um aplicação em rust para treinar uma rede neural</a></li>
<li><a href="#carregamento-do-conjunto-de-dados-mnist">Carregamento do conjunto de dados MNIST</a><ul>
<li><a href="#configuracao-do-dispositivo-de-processamento">Configuração do dispositivo de processamento</a></li>
<li><a href="#criando-um-modelo-deep-learning">Criando um modelo deep learning</a></li>
<li><a href="#treinamento">Treinamento</a></li>
</ul>
</li>
<li><a href="#executando-a-aplicacao-com-cuda-no-supercomputador">Executando a aplicação com cuda no supercomputador</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="instalando-dependencias">Instalando dependências<a class="headerlink" href="#instalando-dependencias" title="Permanent link">&para;</a></h2>
<p>Primeiro instale o rust toolchain na sua pasta HOME, no nó de login.</p>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>curl<span class="w"> </span>--proto<span class="w"> </span><span class="s1">&#39;=https&#39;</span><span class="w"> </span>--tlsv1.2<span class="w"> </span>-sSf<span class="w"> </span>https://sh.rustup.rs<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh
</code></pre></div>
<p>segundo crie um novo projeto rust com cargo chamado pytorch-example. Para esse projeto Adicione as dependências:</p>
<ul>
<li><strong>anyhow</strong>, uma biblioteca para facilita o tratamento de erro em rust</li>
<li><strong>tch</strong> O framework Pytorch para criação de modelos deep learning escrito em C++, mas com bindings para rust</li>
</ul>
<div class="highlight"><pre><span></span><code>cargo<span class="w"> </span>new<span class="w"> </span>pytorch-example
<span class="nb">cd</span><span class="w"> </span>pytorch-example
cargo<span class="w"> </span>add<span class="w"> </span>anyhow
cargo<span class="w"> </span>add<span class="w"> </span>tch
</code></pre></div>
<h2 id="criando-um-aplicacao-em-rust-para-treinar-uma-rede-neural">Criando um aplicação em rust para treinar uma rede neural<a class="headerlink" href="#criando-um-aplicacao-em-rust-para-treinar-uma-rede-neural" title="Permanent link">&para;</a></h2>
<p>A aplicação escrita  em rust, deverá selecionar qual dispositivo de processamento, CPU ou GPU, deverá ser usado para a execução dos cálculos numéricos.
Carregar o conjunto de dados MNIST para ser computado em tal dispositivo. Criar um modelo deep learning e treinar o modelo. Portanto podemos entender
a aplicação em  4 partes importantes:  carregamento do conjunto de dados MNIST, configuração do dispositivo, criando um modelo deep learning, treinamento.</p>
<h2 id="carregamento-do-conjunto-de-dados-mnist">Carregamento do conjunto de dados MNIST<a class="headerlink" href="#carregamento-do-conjunto-de-dados-mnist" title="Permanent link">&para;</a></h2>
<p>Como o MNIST é um conjunto de dados muito famoso, o próprio pytorch possui mecanismos de carregá-lo, desde que você tenha ele baixado e descompactado.
Para baixar o dataset, você pode criar um script similar ao <a href="https://github.com/samuel-cavalcanti/tch-rs-example/blob/main/get_inputs.sh">get_inputs.sh</a>. Onde basicamente ele cria o diretório chamado <strong>data</strong>
e baixa os arquivos do dataset e os extrai com <strong>gunzip</strong></p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash </span>
<span class="c1"># get_inputs.sh</span>
mkdir<span class="w"> </span>data<span class="w"> </span>-p
<span class="nb">cd</span><span class="w"> </span>data
wget<span class="w"> </span>http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz<span class="p">;</span><span class="w"> </span>gunzip<span class="w"> </span>train-images-idx3-ubyte.gz
wget<span class="w"> </span>http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz<span class="p">;</span><span class="w"> </span>gunzip<span class="w"> </span>train-labels-idx1-ubyte.gz
wget<span class="w"> </span>http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz<span class="p">;</span><span class="w"> </span>gunzip<span class="w"> </span>t10k-images-idx3-ubyte.gz
wget<span class="w"> </span>http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz<span class="p">;</span><span class="w"> </span>gunzip<span class="w"> </span>t10k-labels-idx1-ubyte.gz
</code></pre></div>
<p>Para carregar o dataset basta usar o a função <strong>tch::vision::mnist::load_dir</strong></p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">match</span><span class="w"> </span><span class="n">tch</span>::<span class="n">vision</span>::<span class="n">mnist</span>::<span class="n">load_dir</span><span class="p">(</span><span class="s">&quot;data&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">Dataset</span>
<span class="w">          </span><span class="nb">Ok</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span>
<span class="w">          </span><span class="nb">Err</span><span class="p">(</span><span class="n">_</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="fm">panic!</span><span class="p">(</span><span class="s">&quot;Dataset Not found, run the get_inputs.sh !!&quot;</span><span class="p">),</span>
<span class="p">};</span>
</code></pre></div>
<h3 id="configuracao-do-dispositivo-de-processamento">Configuração do dispositivo de processamento<a class="headerlink" href="#configuracao-do-dispositivo-de-processamento" title="Permanent link">&para;</a></h3>
<p>Utilizando um framework pytorch podemos selecionar o dispositivo da seguinte forma, se uma <strong>GPU</strong> estiver disponível, então utilize GPU. Caso o contrário utilize
<strong>CPU</strong>. Com o dispositivo podemos criar um conjunto de tensores cujo seus valores <strong>variam</strong> e que esses valores deverão ser capazes de serem armazenados, ou seja
criamos uma <strong>VarStore</strong>.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="kd">let</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tch</span>::<span class="n">Device</span>::<span class="n">cuda_if_available</span><span class="p">();</span>
<span class="w"> </span><span class="kd">let</span><span class="w"> </span><span class="n">vs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tch</span>::<span class="n">nn</span>::<span class="n">VarStore</span>::<span class="n">new</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">clone</span><span class="p">());</span>
</code></pre></div>
<p>Também precisamos transformar ou mover os dados do conjunto de dados para o dispositivo de processamento</p>
<div class="highlight"><pre><span></span><code><span class="k">fn</span> <span class="nf">dataset_to_device</span><span class="p">(</span><span class="n">dataset</span>: <span class="nc">Dataset</span><span class="p">,</span><span class="w"> </span><span class="n">device</span>: <span class="kp">&amp;</span><span class="nc">Device</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="nc">Dataset</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">train_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">.</span><span class="n">train_labels</span><span class="p">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">clone</span><span class="p">());</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">train_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">.</span><span class="n">train_images</span><span class="p">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">clone</span><span class="p">());</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">test_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">.</span><span class="n">test_labels</span><span class="p">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">clone</span><span class="p">());</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">test_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">.</span><span class="n">test_images</span><span class="p">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">clone</span><span class="p">());</span>

<span class="w">    </span><span class="n">Dataset</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">test_images</span><span class="p">,</span>
<span class="w">        </span><span class="n">test_labels</span><span class="p">,</span>
<span class="w">        </span><span class="n">train_images</span><span class="p">,</span>
<span class="w">        </span><span class="n">train_labels</span><span class="p">,</span>
<span class="w">        </span><span class="n">labels</span>: <span class="nc">dataset</span><span class="p">.</span><span class="n">labels</span><span class="p">,</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="kd">let</span><span class="w"> </span><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset_to_device</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">);</span>
</code></pre></div>
<h3 id="criando-um-modelo-deep-learning">Criando um modelo deep learning<a class="headerlink" href="#criando-um-modelo-deep-learning" title="Permanent link">&para;</a></h3>
<p>O modelo deep learning utilizado nesse exemplo será um modelo sequencial simples e com poucas camadas. Em rust o modelo
ficou assim:</p>
<div class="highlight"><pre><span></span><code><span class="k">use</span><span class="w"> </span><span class="n">tch</span>::<span class="p">{</span><span class="n">nn</span><span class="p">,</span><span class="w"> </span><span class="n">nn</span>::<span class="n">Module</span><span class="p">};</span>
<span class="k">const</span><span class="w"> </span><span class="n">IMAGE_DIM</span>: <span class="kt">i64</span> <span class="o">=</span><span class="w"> </span><span class="mi">784</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="n">HIDDEN_NODES</span>: <span class="kt">i64</span> <span class="o">=</span><span class="w"> </span><span class="mi">128</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="n">LABELS</span>: <span class="kt">i64</span> <span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">net</span><span class="p">(</span><span class="n">vs</span>: <span class="kp">&amp;</span><span class="nc">nn</span>::<span class="n">Path</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="nc">impl</span><span class="w"> </span><span class="n">Module</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">nn</span>::<span class="n">seq</span><span class="p">()</span>
<span class="w">        </span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span>::<span class="n">linear</span><span class="p">(</span>
<span class="w">            </span><span class="n">vs</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="s">&quot;layer1&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="n">IMAGE_DIM</span><span class="p">,</span>
<span class="w">            </span><span class="n">HIDDEN_NODES</span><span class="p">,</span>
<span class="w">            </span><span class="nb">Default</span>::<span class="n">default</span><span class="p">(),</span>
<span class="w">        </span><span class="p">))</span>
<span class="w">        </span><span class="p">.</span><span class="n">add_fn</span><span class="p">(</span><span class="o">|</span><span class="n">xs</span><span class="o">|</span><span class="w"> </span><span class="n">xs</span><span class="p">.</span><span class="n">relu</span><span class="p">())</span>
<span class="w">        </span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span>::<span class="n">linear</span><span class="p">(</span><span class="n">vs</span><span class="p">,</span><span class="w"> </span><span class="n">HIDDEN_NODES</span><span class="p">,</span><span class="w"> </span><span class="n">LABELS</span><span class="p">,</span><span class="w"> </span><span class="nb">Default</span>::<span class="n">default</span><span class="p">()))</span>
<span class="p">}</span>

<span class="kd">let</span><span class="w"> </span><span class="n">net</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">(</span><span class="o">&amp;</span><span class="n">vs</span><span class="p">.</span><span class="n">root</span><span class="p">());</span>
</code></pre></div>
<p>Observe que vs (VarStore) é passada na função <strong>net</strong>, de modo que criar uma camada, ou módulo (layer) é alocar novos de tensores, para a variável.</p>
<h3 id="treinamento">Treinamento<a class="headerlink" href="#treinamento" title="Permanent link">&para;</a></h3>
<p>Para treinar uma rede neural, pode-se utilizar vários algoritmos de otimização, porém nesse exemplo foi utilizado o <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">Adam</a>,
com uma taxa de aprendizado de <strong>0.001</strong>. O modelo será treinado durante 200 interações. Em rust a implementação do treinamento fica da seguinte forma</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">opt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nn</span>::<span class="n">Adam</span>::<span class="n">default</span><span class="p">().</span><span class="n">build</span><span class="p">(</span><span class="o">&amp;</span><span class="n">vs</span><span class="p">,</span><span class="w"> </span><span class="mf">1e-3</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>

<span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="mi">200</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span>
<span class="w">            </span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dataset</span><span class="p">.</span><span class="n">train_images</span><span class="p">)</span>
<span class="w">            </span><span class="p">.</span><span class="n">cross_entropy_for_logits</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dataset</span><span class="p">.</span><span class="n">train_labels</span><span class="p">);</span>
<span class="w">        </span><span class="n">opt</span><span class="p">.</span><span class="n">backward_step</span><span class="p">(</span><span class="o">&amp;</span><span class="n">loss</span><span class="p">);</span>
<span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">test_accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span>
<span class="w">            </span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dataset</span><span class="p">.</span><span class="n">test_images</span><span class="p">)</span>
<span class="w">            </span><span class="p">.</span><span class="n">accuracy_for_logits</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dataset</span><span class="p">.</span><span class="n">test_labels</span><span class="p">);</span>
<span class="w">        </span><span class="fm">println!</span><span class="p">(</span>
<span class="w">            </span><span class="s">&quot;epoch: {:4} train loss: {:8.5} test acc: {:5.2}% is cuda: {}&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="n">epoch</span><span class="p">,</span>
<span class="w">            </span><span class="kt">f64</span>::<span class="n">try_from</span><span class="p">(</span><span class="o">&amp;</span><span class="n">loss</span><span class="p">)</span><span class="o">?</span><span class="p">,</span>
<span class="w">            </span><span class="mf">100.</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="kt">f64</span>::<span class="n">try_from</span><span class="p">(</span><span class="o">&amp;</span><span class="n">test_accuracy</span><span class="p">)</span><span class="o">?</span><span class="p">,</span>
<span class="w">            </span><span class="n">device</span><span class="p">.</span><span class="n">is_cuda</span><span class="p">(),</span>
<span class="w">        </span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
</code></pre></div>
<p>Você pode ver a implementação completa em <a href="https://github.com/samuel-cavalcanti/tch-rs-example/blob/main/src/main.rs">main.rs</a></p>
<h2 id="executando-a-aplicacao-com-cuda-no-supercomputador">Executando a aplicação com cuda no supercomputador<a class="headerlink" href="#executando-a-aplicacao-com-cuda-no-supercomputador" title="Permanent link">&para;</a></h2>
<p>Atualmente o supercomputador no NPAD possui uma partição chamada <strong>gpu</strong>, nessa partição encontram-se os nós com GPUs bem potentes capazes de executar a aplicação em 1 segundo.</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash </span>
<span class="c1">#SBATCH --job-name=neural_train</span>
<span class="c1">#SBATCH --time=0-0:15</span>
<span class="c1">#SBATCH --partition=gpu</span>
<span class="c1">#SBATCH --exclusive</span>

<span class="c1"># informando ao tch-rs que desejo compilar com cuda na versão 11.7</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TORCH_CUDA_VERSION</span><span class="o">=</span>cu117

cargo<span class="w"> </span>r<span class="w"> </span>--release
</code></pre></div>
<p>Cargo é o gerenciador de pacotes official da linguagem Rust, perceba que ao executar o comando <code>cargo r --release</code>. A aplicação cargo irá compilar a aplicação utilizando flags de otimização e irá executar o programa. Caso tenha compilado a aplicação no nó de login, será necessário remover a pasta <strong>target</strong>, antes de submeter o script</p>
<div class="highlight"><pre><span></span><code><span class="c1"># rm -rf target # caso tenha compilado a aplicação no nó de login.</span>

sbatch<span class="w"> </span>run_on_superpc.sh
</code></pre></div>
<p>o script <strong>run_on_superpc.sh</strong> pode ser encontrado <a href="https://github.com/samuel-cavalcanti/tch-rs-example/blob/main/run_on_superpc.sh">aqui</a>. Todo o projeto pode ser encontrado no github <a href="https://github.com/samuel-cavalcanti/tch-rs-example">github.com/samuel-cavalcanti/tch-rs-example</a></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Navegação no rodapé">
        <a href="../mpi_tutorial/" class="btn btn-neutral float-left" title="Tutorial de MPI"><span class="icon icon-circle-arrow-left"></span> Anterior</a>
        <a href="../jupyter_tutorial/" class="btn btn-neutral float-right" title="Usando o Jupyter no supercomputador">Seguinte <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Construído com <a href="https://www.mkdocs.org/">MkDocs</a> usando <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provido por <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versões">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../mpi_tutorial/" style="color: #fcfcfc">&laquo; Anterior</a></span>
    
    
      <span><a href="../jupyter_tutorial/" style="color: #fcfcfc">Seguinte &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
